{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO0XJwiJW3R5O6FIK73aAu4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HayateSato/DS_Practice/blob/main/Datacamp_sample_exam_for_DS501.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Practical Exam: Supermarket Loyalty\n",
        "\n",
        "International Essentials is an international supermarket chain.\n",
        "\n",
        "Shoppers at their supermarkets can sign up for a loyalty program that provides rewards each year to customers based on their spending. The more you spend the bigger the rewards.\n",
        "\n",
        "The supermarket would like to be able to predict the likely amount customers in the program will spend, so they can estimate the cost of the rewards.\n",
        "\n",
        "This will help them to predict the likely profit at the end of the year.\n",
        "\n",
        "## Data\n",
        "\n",
        "The dataset contains records of customers for their last full year of the loyalty program.\n",
        "\n",
        "| Column Name | Criteria                                                |\n",
        "|-------------|---------------------------------------------------------|\n",
        "|customer_id | Unique identifier for the customer. </br>Missing values are not possible due to the database structure. |\n",
        "|spend | Continuous. </br>The total spend of the customer in their last full year. This can be any positive value to two decimal places. </br>Missing values should be replaced with 0. |\n",
        "|first_month | Continuous. </br>The amount spent by the customer in their first month of the year. This can be any positive value, rounded to two decimal places. </br>Missing values should be replaced with 0. |\n",
        "| items_in_first_month | Discrete. </br>The number of items purchased in the first month. Any integer value greater than or equal to zero. </br>Missing values should be replaced by 0. |  \n",
        "| region | Nominal. </br>The geographic region that the customer is based in. One of four values Americas, Asia/Pacific, Europe, Middle East/Africa. </br>Missing values should be replaced with \"Unknown\". |\n",
        "| loyalty_years | Oridinal. </br>The number of years the customer has been a part of the loyalty program. One of five ordered categories, '0-1', '1-3', '3-5', '5-10', '10+'. </br>Missing values should be replaced with '0-1'.|\n",
        "| joining_month | Nominal. </br>The month the customer joined the loyalty program. One of 12 values \"Jan\", \"Feb\", \"Mar\", \"Apr\", etc. </br>Missing values should be replaced with \"Unknown\".|\n",
        "| promotion | Nominal. </br>Did the customer join the loyalty program as part of a promotion? Either 'Yes' or 'No'. </br>Missing values should be replaced with 'No'.|\n"
      ],
      "metadata": {
        "id": "WZEFVC1tpM9I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 1\n",
        "\n",
        "Before you fit any models, you will need to make sure the data is clean.\n",
        "\n",
        "The table below shows what the data should look like.\n",
        "\n",
        "Create a cleaned version of the dataframe.\n",
        "\n",
        " - You should start with the data in the file \"loyalty.csv\".\n",
        "\n",
        " - Your output should be a dataframe named `clean_data`.\n",
        "\n",
        " - All column names and values should match the table below.\n",
        "\n",
        "| Column Name | Criteria                                                |\n",
        "|-------------|---------------------------------------------------------|\n",
        "|customer_id | Unique identifier for the customer. </br>Missing values are not possible due to the database structure. |\n",
        "|spend | Continuous. </br>The total spend of the customer in their last full year. This can be any positive value to two decimal places. </br>Missing values should be replaced with 0. |\n",
        "|first_month | Continuous. </br>The amount spent by the customer in their first month of the year. This can be any positive value, rounded to two decimal places. </br>Missing values should be replaced with 0. |\n",
        "| items_in_first_month | Discrete. </br>The number of items purchased in the first month. Any integer value greater than or equal to zero. </br>Missing values should be replaced by 0. |  \n",
        "| region | Nominal. </br>The geographic region that the customer is based in. One of four values Americas, Asia/Pacific, Europe, Middle East/Africa. </br>Missing values should be replaced with \"Unknown\". |\n",
        "| loyalty_years | Oridinal. </br>The number of years the customer has been a part of the loyalty program. One of five ordered categories, '0-1', '1-3', '3-5', '5-10', '10+'. </br>Missing values should be replaced with '0-1'.|\n",
        "| joining_month | Nominal. </br>The month the customer joined the loyalty program. One of 12 values \"Jan\", \"Feb\", \"Mar\", \"Apr\", etc. </br>Missing values should be replaced with \"Unknown\".|\n",
        "| promotion | Nominal. </br>Did the customer join the loyalty program as part of a promotion? Either 'Yes' or 'No'. </br>Missing values should be replaced with 'No'.|"
      ],
      "metadata": {
        "id": "Gc3piLqUpNGo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "OpjIuO6Mo-mg",
        "outputId": "0b337670-5ebd-4bab-a29f-e7c17cbaa78d"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'loyalty.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-f4094d1bf212>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loyalty.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m# print(df.info())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'loyalty.csv'"
          ]
        }
      ],
      "source": [
        "# Use this cell to write your code for Task 1\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "df = pd.read_csv(\"loyalty.csv\")\n",
        "# print(df.info())\n",
        "\n",
        "### customer_id | chaniging to str\n",
        "# df[\"customer_id\"] = df[\"customer_id\"].astype(str)\n",
        "\n",
        "### spend | clean\n",
        "# # # # # # # # #\n",
        "\n",
        "### first_month | replacing \".\" with 0 | adjusting 1 decimal to 2 decimal places\n",
        "df = df.replace(to_replace=\".\", value=\"0\")\n",
        "df[\"first_month\"] = df[\"first_month\"].astype(float)\n",
        "df[\"first_month\"] = round(df[\"first_month\"], 2) # df[\"first_month\"] = df[\"first_month\"].apply(lambda x: \"{:.2f}\".format(x))\n",
        "\n",
        "### items_in_first_month | clean\n",
        "# # # # # # # # #\n",
        "\n",
        "### region | clean, One-hot enconding\n",
        "# df = pd.get_dummies(df, columns=[\"region\"], drop_first=True)\n",
        "\n",
        "### loyalty_years | clean, One-hot enconding\n",
        "# df = pd.get_dummies(df, columns=[\"loyalty_years\"], drop_first=True)\n",
        "\n",
        "### joining_month | replacing na with \"Unknown\" | One-hot enconding\n",
        "df[\"joining_month\"].fillna(\"Unknown\", inplace=True)\n",
        "# df = pd.get_dummies(df, columns=[\"joining_month\"], drop_first=True)\n",
        "\n",
        "### promotion | converting to lower_case | One-hot enconding\n",
        "promo_map = { 'YES' : 'Yes', 'NO' : 'No'}\n",
        "df[\"promotion\"] = df[\"promotion\"].replace(promo_map)  # df[\"promotion\"] = [x.lower() for x in df[\"promotion\"]]\n",
        "# df = pd.get_dummies(df, columns=[\"promotion\"], drop_first=True)\n",
        "\n",
        "### lowering the col\n",
        "df.columns = [x.lower() for x in df.columns]\n",
        "\n",
        "# print(df.info())\n",
        "\n",
        "clean_data = df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 2\n",
        "\n",
        "The team at International Essentials have told you that they have always believed that the number of years in the loyalty scheme is the biggest driver of spend.\n",
        "\n",
        "Producing a table showing the difference in the average spend by number of years in the loyalty programme along with the variance to investigate this question for the team.\n",
        "\n",
        " - You should start with the data in the file 'loyalty.csv'.\n",
        "\n",
        " - Your output should be a data frame named `spend_by_years`.\n",
        "\n",
        " - It should include the three columns `loyalty_years`, `avg_spend`, `var_spend`.\n",
        "\n",
        " - Your answers should be rounded to 2 decimal places.   "
      ],
      "metadata": {
        "id": "PFAIcbcYpNJI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"loyalty.csv\")\n",
        "\n",
        "df_grouped = df.groupby('loyalty_years').agg(\n",
        "    avg_spend=('spend', 'mean'),    # Calculate average spend\n",
        "    var_spend=('spend', 'var')      # Calculate variance of spend\n",
        ")\n",
        "\n",
        "# Step 2: Reset the index to make 'loyalty_years' a column if needed\n",
        "df_grouped = df_grouped.reset_index()\n",
        "\n",
        "# Step 3: Create the new DataFrame with the required columns\n",
        "spend_by_years = df_grouped[['loyalty_years', 'avg_spend', 'var_spend']]\n",
        "spend_by_years = round(spend_by_years, 2)\n",
        "\n",
        "# Display the new DataFrame\n",
        "print(spend_by_years)"
      ],
      "metadata": {
        "id": "UIYKpT1Wpcbg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 3\n",
        "\n",
        "Fit a baseline model to predict the spend over the year for each customer.\n",
        "\n",
        " 1. Fit your model using the data contained in “train.csv” </br></br>\n",
        "\n",
        " 2. Use “test.csv” to predict new values based on your model. You must return a dataframe named `base_result`, that includes `customer_id` and `spend`. The `spend` column must be your predicted values."
      ],
      "metadata": {
        "id": "BEv28_qSpfPP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "import pandas as pd\n",
        "\n",
        "print(train_df.info())\n",
        "print(test_df.info())\n",
        "\n",
        "# Use this cell to write your code for task 3\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Import data\n",
        "train = pd.read_csv('train.csv')\n",
        "val = pd.read_csv('test.csv')\n",
        "\n",
        "# onehot encoding for categorial col\n",
        "train = pd.get_dummies(train, columns=[\"region\", \"loyalty_years\", \"joining_month\", \"promotion\"])\n",
        "val = pd.get_dummies(val, columns=[\"region\", \"loyalty_years\", \"joining_month\", \"promotion\"])\n",
        "\n",
        "# lowering the cases of col\n",
        "train.columns = [x.lower() for x in train.columns]\n",
        "val.columns = [x.lower() for x in val.columns]\n",
        "\n",
        "# drop customer_id\n",
        "train_noid = train.drop(columns=['customer_id'])\n",
        "val_noid = val.drop(columns=['customer_id'])\n",
        "\n",
        "# # synthetically creating \"spend\" for val_noid\n",
        "# val_noid['spend'] = np.nan\n",
        "# val_noid['spend'].fillna(0, inplace=True)\n",
        "\n",
        "# Instantiate the linear model\n",
        "model = LinearRegression()\n",
        "\n",
        "# Create X and y variables\n",
        "X = train_noid.drop('spend', axis=1).values\n",
        "y = train_noid['spend'].values\n",
        "\n",
        "# Fit the model to the training data\n",
        "model.fit(X, y)\n",
        "\n",
        "# Predict values based on val_data\n",
        "predicted_spendeture = model.predict(val_noid)\n",
        "\n",
        "# Create dataframe of predicted values\n",
        "base_result = pd.DataFrame({'customer_id':val['customer_id'],\n",
        "                            'spend':predicted_spendeture})\n",
        "base_result"
      ],
      "metadata": {
        "id": "gV9DXFvopim5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}