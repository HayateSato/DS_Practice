{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNRNhWWGATOJMKVJkVHtRZB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HayateSato/DS_Practice/blob/main/scikit_learn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "C9T8fGzVKp-y"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import roc_curve, auc"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the dataset\n",
        "=="
      ],
      "metadata": {
        "id": "4NDyQZp-PuiH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "y_binary = (y == 1).astype(int)  # Convert to binary classification by changing eveything that is not 1 to 0\n",
        "# y_binary_2 = (y == 2).astype(int)"
      ],
      "metadata": {
        "id": "GXR5ASyIL1zs"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2l7qTF81YhH",
        "outputId": "135e1194-4be7-4167-8eda-0adc0b4d2bed"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'data': array([[5.1, 3.5, 1.4, 0.2],\n",
              "        [4.9, 3. , 1.4, 0.2],\n",
              "        [4.7, 3.2, 1.3, 0.2],\n",
              "        [4.6, 3.1, 1.5, 0.2],\n",
              "        [5. , 3.6, 1.4, 0.2],\n",
              "        [5.4, 3.9, 1.7, 0.4],\n",
              "        [4.6, 3.4, 1.4, 0.3],\n",
              "        [5. , 3.4, 1.5, 0.2],\n",
              "        [4.4, 2.9, 1.4, 0.2],\n",
              "        [4.9, 3.1, 1.5, 0.1],\n",
              "        [5.4, 3.7, 1.5, 0.2],\n",
              "        [4.8, 3.4, 1.6, 0.2],\n",
              "        [4.8, 3. , 1.4, 0.1],\n",
              "        [4.3, 3. , 1.1, 0.1],\n",
              "        [5.8, 4. , 1.2, 0.2],\n",
              "        [5.7, 4.4, 1.5, 0.4],\n",
              "        [5.4, 3.9, 1.3, 0.4],\n",
              "        [5.1, 3.5, 1.4, 0.3],\n",
              "        [5.7, 3.8, 1.7, 0.3],\n",
              "        [5.1, 3.8, 1.5, 0.3],\n",
              "        [5.4, 3.4, 1.7, 0.2],\n",
              "        [5.1, 3.7, 1.5, 0.4],\n",
              "        [4.6, 3.6, 1. , 0.2],\n",
              "        [5.1, 3.3, 1.7, 0.5],\n",
              "        [4.8, 3.4, 1.9, 0.2],\n",
              "        [5. , 3. , 1.6, 0.2],\n",
              "        [5. , 3.4, 1.6, 0.4],\n",
              "        [5.2, 3.5, 1.5, 0.2],\n",
              "        [5.2, 3.4, 1.4, 0.2],\n",
              "        [4.7, 3.2, 1.6, 0.2],\n",
              "        [4.8, 3.1, 1.6, 0.2],\n",
              "        [5.4, 3.4, 1.5, 0.4],\n",
              "        [5.2, 4.1, 1.5, 0.1],\n",
              "        [5.5, 4.2, 1.4, 0.2],\n",
              "        [4.9, 3.1, 1.5, 0.2],\n",
              "        [5. , 3.2, 1.2, 0.2],\n",
              "        [5.5, 3.5, 1.3, 0.2],\n",
              "        [4.9, 3.6, 1.4, 0.1],\n",
              "        [4.4, 3. , 1.3, 0.2],\n",
              "        [5.1, 3.4, 1.5, 0.2],\n",
              "        [5. , 3.5, 1.3, 0.3],\n",
              "        [4.5, 2.3, 1.3, 0.3],\n",
              "        [4.4, 3.2, 1.3, 0.2],\n",
              "        [5. , 3.5, 1.6, 0.6],\n",
              "        [5.1, 3.8, 1.9, 0.4],\n",
              "        [4.8, 3. , 1.4, 0.3],\n",
              "        [5.1, 3.8, 1.6, 0.2],\n",
              "        [4.6, 3.2, 1.4, 0.2],\n",
              "        [5.3, 3.7, 1.5, 0.2],\n",
              "        [5. , 3.3, 1.4, 0.2],\n",
              "        [7. , 3.2, 4.7, 1.4],\n",
              "        [6.4, 3.2, 4.5, 1.5],\n",
              "        [6.9, 3.1, 4.9, 1.5],\n",
              "        [5.5, 2.3, 4. , 1.3],\n",
              "        [6.5, 2.8, 4.6, 1.5],\n",
              "        [5.7, 2.8, 4.5, 1.3],\n",
              "        [6.3, 3.3, 4.7, 1.6],\n",
              "        [4.9, 2.4, 3.3, 1. ],\n",
              "        [6.6, 2.9, 4.6, 1.3],\n",
              "        [5.2, 2.7, 3.9, 1.4],\n",
              "        [5. , 2. , 3.5, 1. ],\n",
              "        [5.9, 3. , 4.2, 1.5],\n",
              "        [6. , 2.2, 4. , 1. ],\n",
              "        [6.1, 2.9, 4.7, 1.4],\n",
              "        [5.6, 2.9, 3.6, 1.3],\n",
              "        [6.7, 3.1, 4.4, 1.4],\n",
              "        [5.6, 3. , 4.5, 1.5],\n",
              "        [5.8, 2.7, 4.1, 1. ],\n",
              "        [6.2, 2.2, 4.5, 1.5],\n",
              "        [5.6, 2.5, 3.9, 1.1],\n",
              "        [5.9, 3.2, 4.8, 1.8],\n",
              "        [6.1, 2.8, 4. , 1.3],\n",
              "        [6.3, 2.5, 4.9, 1.5],\n",
              "        [6.1, 2.8, 4.7, 1.2],\n",
              "        [6.4, 2.9, 4.3, 1.3],\n",
              "        [6.6, 3. , 4.4, 1.4],\n",
              "        [6.8, 2.8, 4.8, 1.4],\n",
              "        [6.7, 3. , 5. , 1.7],\n",
              "        [6. , 2.9, 4.5, 1.5],\n",
              "        [5.7, 2.6, 3.5, 1. ],\n",
              "        [5.5, 2.4, 3.8, 1.1],\n",
              "        [5.5, 2.4, 3.7, 1. ],\n",
              "        [5.8, 2.7, 3.9, 1.2],\n",
              "        [6. , 2.7, 5.1, 1.6],\n",
              "        [5.4, 3. , 4.5, 1.5],\n",
              "        [6. , 3.4, 4.5, 1.6],\n",
              "        [6.7, 3.1, 4.7, 1.5],\n",
              "        [6.3, 2.3, 4.4, 1.3],\n",
              "        [5.6, 3. , 4.1, 1.3],\n",
              "        [5.5, 2.5, 4. , 1.3],\n",
              "        [5.5, 2.6, 4.4, 1.2],\n",
              "        [6.1, 3. , 4.6, 1.4],\n",
              "        [5.8, 2.6, 4. , 1.2],\n",
              "        [5. , 2.3, 3.3, 1. ],\n",
              "        [5.6, 2.7, 4.2, 1.3],\n",
              "        [5.7, 3. , 4.2, 1.2],\n",
              "        [5.7, 2.9, 4.2, 1.3],\n",
              "        [6.2, 2.9, 4.3, 1.3],\n",
              "        [5.1, 2.5, 3. , 1.1],\n",
              "        [5.7, 2.8, 4.1, 1.3],\n",
              "        [6.3, 3.3, 6. , 2.5],\n",
              "        [5.8, 2.7, 5.1, 1.9],\n",
              "        [7.1, 3. , 5.9, 2.1],\n",
              "        [6.3, 2.9, 5.6, 1.8],\n",
              "        [6.5, 3. , 5.8, 2.2],\n",
              "        [7.6, 3. , 6.6, 2.1],\n",
              "        [4.9, 2.5, 4.5, 1.7],\n",
              "        [7.3, 2.9, 6.3, 1.8],\n",
              "        [6.7, 2.5, 5.8, 1.8],\n",
              "        [7.2, 3.6, 6.1, 2.5],\n",
              "        [6.5, 3.2, 5.1, 2. ],\n",
              "        [6.4, 2.7, 5.3, 1.9],\n",
              "        [6.8, 3. , 5.5, 2.1],\n",
              "        [5.7, 2.5, 5. , 2. ],\n",
              "        [5.8, 2.8, 5.1, 2.4],\n",
              "        [6.4, 3.2, 5.3, 2.3],\n",
              "        [6.5, 3. , 5.5, 1.8],\n",
              "        [7.7, 3.8, 6.7, 2.2],\n",
              "        [7.7, 2.6, 6.9, 2.3],\n",
              "        [6. , 2.2, 5. , 1.5],\n",
              "        [6.9, 3.2, 5.7, 2.3],\n",
              "        [5.6, 2.8, 4.9, 2. ],\n",
              "        [7.7, 2.8, 6.7, 2. ],\n",
              "        [6.3, 2.7, 4.9, 1.8],\n",
              "        [6.7, 3.3, 5.7, 2.1],\n",
              "        [7.2, 3.2, 6. , 1.8],\n",
              "        [6.2, 2.8, 4.8, 1.8],\n",
              "        [6.1, 3. , 4.9, 1.8],\n",
              "        [6.4, 2.8, 5.6, 2.1],\n",
              "        [7.2, 3. , 5.8, 1.6],\n",
              "        [7.4, 2.8, 6.1, 1.9],\n",
              "        [7.9, 3.8, 6.4, 2. ],\n",
              "        [6.4, 2.8, 5.6, 2.2],\n",
              "        [6.3, 2.8, 5.1, 1.5],\n",
              "        [6.1, 2.6, 5.6, 1.4],\n",
              "        [7.7, 3. , 6.1, 2.3],\n",
              "        [6.3, 3.4, 5.6, 2.4],\n",
              "        [6.4, 3.1, 5.5, 1.8],\n",
              "        [6. , 3. , 4.8, 1.8],\n",
              "        [6.9, 3.1, 5.4, 2.1],\n",
              "        [6.7, 3.1, 5.6, 2.4],\n",
              "        [6.9, 3.1, 5.1, 2.3],\n",
              "        [5.8, 2.7, 5.1, 1.9],\n",
              "        [6.8, 3.2, 5.9, 2.3],\n",
              "        [6.7, 3.3, 5.7, 2.5],\n",
              "        [6.7, 3. , 5.2, 2.3],\n",
              "        [6.3, 2.5, 5. , 1.9],\n",
              "        [6.5, 3. , 5.2, 2. ],\n",
              "        [6.2, 3.4, 5.4, 2.3],\n",
              "        [5.9, 3. , 5.1, 1.8]]),\n",
              " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
              " 'frame': None,\n",
              " 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10'),\n",
              " 'DESCR': '.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n:Number of Instances: 150 (50 in each of three classes)\\n:Number of Attributes: 4 numeric, predictive attributes and the class\\n:Attribute Information:\\n    - sepal length in cm\\n    - sepal width in cm\\n    - petal length in cm\\n    - petal width in cm\\n    - class:\\n            - Iris-Setosa\\n            - Iris-Versicolour\\n            - Iris-Virginica\\n\\n:Summary Statistics:\\n\\n============== ==== ==== ======= ===== ====================\\n                Min  Max   Mean    SD   Class Correlation\\n============== ==== ==== ======= ===== ====================\\nsepal length:   4.3  7.9   5.84   0.83    0.7826\\nsepal width:    2.0  4.4   3.05   0.43   -0.4194\\npetal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\npetal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n============== ==== ==== ======= ===== ====================\\n\\n:Missing Attribute Values: None\\n:Class Distribution: 33.3% for each of 3 classes.\\n:Creator: R.A. Fisher\\n:Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n:Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. dropdown:: References\\n\\n  - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n    Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n    Mathematical Statistics\" (John Wiley, NY, 1950).\\n  - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n    (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n  - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n    Structure and Classification Rule for Recognition in Partially Exposed\\n    Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n    Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n  - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n    on Information Theory, May 1972, 431-433.\\n  - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n    conceptual clustering system finds 3 classes in the data.\\n  - Many, many more ...\\n',\n",
              " 'feature_names': ['sepal length (cm)',\n",
              "  'sepal width (cm)',\n",
              "  'petal length (cm)',\n",
              "  'petal width (cm)'],\n",
              " 'filename': 'iris.csv',\n",
              " 'data_module': 'sklearn.datasets.data'}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bUMavJeu1Yk1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_binary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JyHXy37QOROj",
        "outputId": "54814282-18b4-46cd-88eb-a6c57b15d5fe"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JrOGWAOJO4-q",
        "outputId": "baf3146c-ae4d-46f0-84c5-7be62c8ddf21"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# y_binary_2"
      ],
      "metadata": {
        "id": "mpZtcATgO7pz"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splitting\n",
        "=="
      ],
      "metadata": {
        "id": "1_qrvxKwPybm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_binary, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "VIHN9gQxPLQj"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ls = [\"X_train\", \"X_test\", \"y_train\", \"y_test\"]\n",
        "\n",
        "for i in ls:\n",
        "    print(eval(i).shape) #without eval( ), the code would not run because inside the list is string while what I want to iterate is variable name"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fVuueFXP2Uj",
        "outputId": "26106000-eaec-4af4-a82d-fcc2b5a418b4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(120, 4)\n",
            "(30, 4)\n",
            "(120,)\n",
            "(30,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lst = [X_train, X_test, y_train, y_test]\n",
        "for i in lst:\n",
        "    print(i.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZATYDtuP4tb",
        "outputId": "1b2d1917-4f5a-4f02-fae7-6f40d76d7860"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(120, 4)\n",
            "(30, 4)\n",
            "(120,)\n",
            "(30,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trainig the model\n",
        "=="
      ],
      "metadata": {
        "id": "TzuJm45TRWwc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create and train the classifier\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "bfIAeUlDQw0j",
        "outputId": "fd2f7383-95c0-496e-d2d0-08d80312e7a8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(random_state=42)</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get predicted probabilities\n",
        "y_scores = model.predict_proba(X_test)[:, 1]  # Probabilities for the positive class\n"
      ],
      "metadata": {
        "id": "ujWQBPrmTAnZ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iukemd0UTC-O",
        "outputId": "fc45bb3b-52a3-4b02-9ba5-455a5158a0e7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.99, 0.  , 0.03, 0.98, 0.84, 0.  , 1.  , 0.07, 0.86, 1.  , 0.07,\n",
              "       0.01, 0.01, 0.01, 0.  , 0.85, 0.  , 1.  , 1.  , 0.01, 0.  , 0.1 ,\n",
              "       0.  , 0.01, 0.02, 0.06, 0.06, 0.  , 0.01, 0.01])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tbzCwaJpAUxD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CwV7oKj2AU0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "z2WBJ0ZZSzMR"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YM5wewBpRZ_C"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use this cell to write your code for Task 1\n",
        "import pandas as pd\n",
        "df = pd.read_csv(\"house_sales.csv\")\n",
        "city_na = df[df[\"city\"] == \"--\"]\n",
        "missing_city = len(city_na)\n",
        "print(missing_city)"
      ],
      "metadata": {
        "id": "Sp70WogqBFx5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use this cell to write your code for Task 2\n",
        "import pandas as pd\n",
        "df = pd.read_csv(\"house_sales.csv\")\n",
        "print(df.info())\n",
        "print(\"\\n=============\\n\")\n",
        "\n",
        "### house_id | chaning to string\n",
        "df['house_id'] = df['house_id'].astype(str)\n",
        "\n",
        "\n",
        "### city | replacing \"--\" with \"Unknown\"\n",
        "df = df.replace(to_replace=\"--\", value=\"Unknown\")\n",
        "\n",
        "\n",
        "### sale_price | clean\n",
        "\n",
        "### sale date | chaniging to date time dtype\n",
        "df[\"sale_date\"] = pd.to_datetime(df[\"sale_date\"])\n",
        "\n",
        "\n",
        "### months_listed | missing values\n",
        "mean_month = round(df[\"months_listed\"].mean(), 1) #5.9\n",
        "df[\"months_listed\"] = df[\"months_listed\"].fillna(mean_month)\n",
        "\n",
        "\n",
        "### bedrooms | clean\n",
        "\n",
        "\n",
        "### house_type | fixing the house_type category\n",
        "house_type_map = {\n",
        "    'Det.': 'Detached',\n",
        "    'Terr.': 'Terraced',\n",
        "    'Semi': 'Semi-detached'\n",
        "}\n",
        "df[\"house_type\"] = df[\"house_type\"].replace(house_type_map)\n",
        "\n",
        "\n",
        "### area | removing \"sqm\" and changing the value to float\n",
        "df['area'] = df['area'].str.replace(' sq.m.', '', regex=False).astype(float)\n",
        "\n",
        "\n",
        "clean_data = df\n",
        "print(clean_data.info())"
      ],
      "metadata": {
        "id": "-k817Nf_BF0X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use this cell to write your code for Task 3\n",
        "import pandas as pd\n",
        "df = pd.read_csv(\"house_sales.csv\")\n",
        "\n",
        "df_grouped = df.groupby('bedrooms').agg(\n",
        "    avg_price=('sale_price', 'mean'),    # Calculate average spend\n",
        "    var_price=('sale_price', 'var')      # Calculate variance of spend\n",
        ")\n",
        "\n",
        "# Step 2: Reset the index to make 'bedrooms' a column if needed\n",
        "df_grouped = df_grouped.reset_index()\n",
        "\n",
        "# Step 3: Create the new DataFrame with the required columns\n",
        "price_by_rooms = df_grouped[['bedrooms', 'avg_price', 'var_price']]\n",
        "price_by_rooms[\"avg_price\"] = round(price_by_rooms[\"avg_price\"], 1)\n",
        "price_by_rooms[\"var_price\"] = round(price_by_rooms[\"var_price\"], 1)\n",
        "\n",
        "#Display the new DataFrame\n",
        "print(price_by_rooms)\n"
      ],
      "metadata": {
        "id": "hnzyofI8BF23"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use this cell to write your code for Task 4\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load the training dataset (this is the only dataset you are provided for training)\n",
        "train_df = pd.read_csv('train.csv')  # Training dataset\n",
        "\n",
        "# Separate features and target from the training dataset\n",
        "X = train_df.drop(columns=['sale_price', 'house_id', 'city', 'sale_date', 'months_listed', 'house_type'])  # Replace 'target' with the actual target column name\n",
        "y = train_df['sale_price']\n",
        "\n",
        "# Split the training data into actual training set and validation set\n",
        "# 80% of the data will be used for training, and 20% for internal validation\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the regression model (Linear Regression in this case)\n",
        "model = LinearRegression()\n",
        "\n",
        "# Train the model on the training data (80% of the original dataset)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the internal validation set (20% of the original dataset)\n",
        "y_valid_pred = model.predict(X_valid)\n",
        "\n",
        "# Evaluate the model on the internal validation set using Mean Squared Error (MSE)\n",
        "mse_valid = mean_squared_error(y_valid, y_valid_pred)\n",
        "print(f\"Internal Validation MSE: {mse_valid}\")\n",
        "\n",
        "# Now, use the actual 'validation' dataset for making predictions (without target values)\n",
        "validation_df = pd.read_csv('validation.csv')  # Validation dataset you were provided\n",
        "\n",
        "# If the validation dataset doesn't have a target column, just make predictions\n",
        "# Remove or ignore any unnecessary columns that aren't features\n",
        "X_test = validation_df  # This contains only the features\n",
        "house_ids = validation_df['house_id']\n",
        "X_test = validation_df.drop(columns=['house_id', 'city', 'sale_date', 'months_listed', 'house_type'])\n",
        "\n",
        "# Predict on the validation dataset (no target available here)\n",
        "y_test_pred = model.predict(X_test)\n",
        "\n",
        "# Optionally, save the predictions to a DataFrame for later use or submission\n",
        "base_result = pd.DataFrame({\n",
        "    'house_id' : house_ids,\n",
        "    'price': y_test_pred\n",
        "})\n",
        "\n",
        "print(base_result)"
      ],
      "metadata": {
        "id": "pewiInrNBF5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use this cell to write your code for Task 5\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load the training dataset (this is the only dataset you are provided for training)\n",
        "train_df = pd.read_csv('train.csv')  # Training dataset\n",
        "\n",
        "# Separate features and target from the training dataset\n",
        "X = train_df.drop(columns=['sale_price', 'house_id', 'city', 'sale_date', 'months_listed', 'house_type'])  # Replace 'target' with the actual target column name\n",
        "y = train_df['sale_price']\n",
        "\n",
        "# Split the training data into actual training set and validation set\n",
        "# 80% of the data will be used for training, and 20% for internal validation\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 1. First Model (Linear Regression)\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)  # Train Linear Regression\n",
        "y_valid_pred = model.predict(X_valid)  # Predict on internal validation set\n",
        "\n",
        "# Evaluate the Linear Regression model on the internal validation set\n",
        "mse_valid = mean_squared_error(y_valid, y_valid_pred)\n",
        "print(f\"Linear Regression Validation MSE: {mse_valid}\")\n",
        "\n",
        "# Now, use the actual 'validation' dataset for making predictions (without target values)\n",
        "validation_df = pd.read_csv('validation.csv')  # Validation dataset you were provided\n",
        "house_ids = validation_df['house_id']  # Store house_id\n",
        "\n",
        "# Drop 'house_id' for prediction\n",
        "X_test = validation_df.drop(columns=['house_id', 'city', 'sale_date', 'months_listed', 'house_type'])\n",
        "y_test_pred = model.predict(X_test)  # Predictions from Linear Regression model\n",
        "\n",
        "# Save the initial predictions (before improvement)\n",
        "base_result = pd.DataFrame({\n",
        "    'house_id': house_ids,\n",
        "    'Predicted Target': y_test_pred\n",
        "})\n",
        "\n",
        "# 2. Improved Model (Random Forest Regressor)\n",
        "improved_model = RandomForestRegressor(n_estimators=100, random_state=42)  # Use Random Forest\n",
        "improved_model.fit(X_train, y_train)  # Train Random Forest\n",
        "\n",
        "# Predict on the validation set again using the improved model\n",
        "y_valid_pred_improved = improved_model.predict(X_valid)\n",
        "\n",
        "# Evaluate the Random Forest model on the internal validation set\n",
        "mse_valid_improved = mean_squared_error(y_valid, y_valid_pred_improved)\n",
        "print(f\"Random Forest Validation MSE: {mse_valid_improved}\")\n",
        "\n",
        "# Predict on the actual validation dataset (used as test set)\n",
        "y_test_pred_improved = improved_model.predict(X_test)\n",
        "\n",
        "# Save the improved predictions and compare them with the original\n",
        "compare_result = pd.DataFrame({\n",
        "    'house_id': house_ids,\n",
        "    'Original Prediction': y_test_pred,  # From Linear Regression\n",
        "    'price': y_test_pred_improved  # From Random Forest\n",
        "})\n",
        "\n",
        "# Optionally, save compare_result to a CSV file\n",
        "# compare_result.to_csv('compare_result.csv', index=False)\n",
        "\n",
        "print(compare_result)"
      ],
      "metadata": {
        "id": "Aj4-9qD6BF7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FNU6aXOPGj44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qBQGcXp0Ghy3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jkj3m2nOGh1o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PekUUeyHGh4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pattern 1\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load the training dataset (this is the only dataset you are provided for training)\n",
        "train_df = pd.read_csv('train_data.csv')  # Training dataset\n",
        "\n",
        "# Separate features and target from the training dataset\n",
        "X = train_df.drop(columns=['target'])  # Replace 'target' with the actual target column name\n",
        "y = train_df['target']\n",
        "\n",
        "# Split the training data into actual training set and validation set\n",
        "# 80% of the data will be used for training, and 20% for internal validation\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 1. First Model (Linear Regression)\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)  # Train Linear Regression\n",
        "y_valid_pred = model.predict(X_valid)  # Predict on internal validation set\n",
        "\n",
        "# Evaluate the Linear Regression model on the internal validation set\n",
        "mse_valid = mean_squared_error(y_valid, y_valid_pred)\n",
        "print(f\"Linear Regression Validation MSE: {mse_valid}\")\n",
        "\n",
        "# Now, use the actual 'validation' dataset for making predictions (without target values)\n",
        "validation_df = pd.read_csv('validation_data.csv')  # Validation dataset you were provided\n",
        "house_ids = validation_df['house_id']  # Store house_id\n",
        "\n",
        "# Drop 'house_id' for prediction\n",
        "X_test = validation_df.drop(columns=['house_id'])\n",
        "y_test_pred = model.predict(X_test)  # Predictions from Linear Regression model\n",
        "\n",
        "# Save the initial predictions (before improvement)\n",
        "predictions_df = pd.DataFrame({\n",
        "    'house_id': house_ids,\n",
        "    'Predicted Target': y_test_pred\n",
        "})\n",
        "\n",
        "# 2. Improved Model (Random Forest Regressor)\n",
        "improved_model = RandomForestRegressor(n_estimators=100, random_state=42)  # Use Random Forest\n",
        "improved_model.fit(X_train, y_train)  # Train Random Forest\n",
        "\n",
        "# Predict on the validation set again using the improved model\n",
        "y_valid_pred_improved = improved_model.predict(X_valid)\n",
        "\n",
        "# Evaluate the Random Forest model on the internal validation set\n",
        "mse_valid_improved = mean_squared_error(y_valid, y_valid_pred_improved)\n",
        "print(f\"Random Forest Validation MSE: {mse_valid_improved}\")\n",
        "\n",
        "# Predict on the actual validation dataset (used as test set)\n",
        "y_test_pred_improved = improved_model.predict(X_test)\n",
        "\n",
        "# Save the improved predictions and compare them with the original\n",
        "compare_result = pd.DataFrame({\n",
        "    'house_id': house_ids,\n",
        "    'Original Prediction': y_test_pred,  # From Linear Regression\n",
        "    'Improved Prediction': y_test_pred_improved  # From Random Forest\n",
        "})\n",
        "\n",
        "# Optionally, save compare_result to a CSV file\n",
        "compare_result.to_csv('compare_result.csv', index=False)\n",
        "\n",
        "print(\"Improved predictions and comparison have been saved.\")"
      ],
      "metadata": {
        "id": "yBbfxFQCBF-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pattern 2\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor  # Example of an improved model\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load the training dataset (this is the only dataset you are provided for training)\n",
        "train_df = pd.read_csv('train_data.csv')  # Training dataset\n",
        "\n",
        "# Separate features and target from the training dataset\n",
        "X = train_df.drop(columns=['target'])  # Replace 'target' with the actual target column name\n",
        "y = train_df['target']\n",
        "\n",
        "# Split the training data into actual training set and validation set\n",
        "# 80% of the data will be used for training, and 20% for internal validation\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# --- Step 1: Build and train the original LinearRegression model ---\n",
        "# Initialize the original regression model (Linear Regression)\n",
        "model = LinearRegression()\n",
        "\n",
        "# Train the model on the training data\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the internal validation set\n",
        "y_valid_pred = model.predict(X_valid)\n",
        "\n",
        "# Evaluate the original model using MSE on the internal validation set\n",
        "mse_valid = mean_squared_error(y_valid, y_valid_pred)\n",
        "print(f\"Original Model - Validation MSE: {mse_valid}\")\n",
        "\n",
        "# Now, use the 'validation' dataset (without target values) for predictions\n",
        "validation_df = pd.read_csv('validation_data.csv')  # Validation dataset you were provided\n",
        "\n",
        "# Keep the house_id column to save it in the predictions DataFrame\n",
        "house_ids = validation_df['house_id']  # Assuming 'house_id' is the column name for house IDs\n",
        "\n",
        "# Drop 'house_id' from the features when making predictions\n",
        "X_test = validation_df.drop(columns=['house_id'])  # Use only features for prediction\n",
        "\n",
        "# Predict on the validation dataset with the original model (no target available here)\n",
        "y_test_pred = model.predict(X_test)\n",
        "\n",
        "# Store the original predictions in a DataFrame\n",
        "predictions_df = pd.DataFrame({\n",
        "    'house_id': house_ids,\n",
        "    'Original Prediction': y_test_pred\n",
        "})\n",
        "\n",
        "# --- Step 2: Build an improved model (e.g., RandomForestRegressor) ---\n",
        "# Initialize a new, potentially better model (Random Forest)\n",
        "improved_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the improved model on the same training data\n",
        "improved_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the same validation set with the improved model\n",
        "y_valid_improved_pred = improved_model.predict(X_valid)\n",
        "\n",
        "# Evaluate the improved model using MSE on the validation set\n",
        "mse_valid_improved = mean_squared_error(y_valid, y_valid_improved_pred)\n",
        "print(f\"Improved Model - Validation MSE: {mse_valid_improved}\")\n",
        "\n",
        "# Predict on the validation dataset using the improved model (no target available here)\n",
        "y_test_improved_pred = improved_model.predict(X_test)\n",
        "\n",
        "# Store the improved model predictions in the DataFrame under \"compare_result\"\n",
        "predictions_df['Improved Prediction'] = y_test_improved_pred\n",
        "\n",
        "# --- Step 3: Compare results in a new DataFrame called 'compare_result' ---\n",
        "compare_result = predictions_df.copy()\n",
        "\n",
        "# Save the comparison to a CSV file (if needed)\n",
        "compare_result.to_csv('compare_result.csv', index=False)\n",
        "\n",
        "print(\"Comparison of original and improved predictions has been saved.\")\n"
      ],
      "metadata": {
        "id": "XcHI9t9zBGBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "import pandas as pd\n",
        "\n",
        "# Load the training and validation datasets\n",
        "train_df_comparison = pd.read_csv('train.csv')\n",
        "validation_df_comparison = pd.read_csv('validation.csv')\n",
        "\n",
        "# Preparing the data for the comparison model\n",
        "X_comparison = train_df_comparison.drop(columns=['house_id', 'sale_price', 'sale_date'])\n",
        "y_comparison = train_df_comparison['sale_price']\n",
        "\n",
        "# Identifying categorical columns in the dataset for the comparison model\n",
        "categorical_cols_comparison = [col for col in X_comparison.columns if X_comparison[col].dtype == 'object']\n",
        "\n",
        "# Creating a transformer for preprocessing in the dataset for the comparison model\n",
        "preprocessor_comparison = ColumnTransformer(\n",
        "transformers=[\n",
        "('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols_comparison),\n",
        "],\n",
        "remainder='passthrough' # keeping other columns untouched\n",
        ")\n",
        "\n",
        "# Creating a pipeline with preprocessing and the Random Forest Regressor for the comparison model\n",
        "model_comparison = Pipeline(steps=[\n",
        "('preprocessor', preprocessor_comparison),\n",
        "('regressor', RandomForestRegressor(n_estimators=100, random_state=42))\n",
        "])\n",
        "\n",
        "# Fitting the model with the dataset for the comparison model\n",
        "model_comparison.fit(X_comparison, y_comparison)\n",
        "print(\"Comparison model (Random Forest Regressor) trained successfully.\")\n",
        "\n",
        "# Preparing the validation data (similar to the training data preparation for the comparison model)\n",
        "X_validation_comparison = validation_df_comparison.drop(columns=['house_id', 'sale_date'])\n",
        "\n",
        "# Making predictions using the trained comparison model\n",
        "validation_df_comparison['price'] = model_comparison.predict(X_validation_comparison)\n",
        "\n",
        "# Creating the compare_result DataFrame with house_id and predicted price\n",
        "compare_result = validation_df_comparison[['house_id', 'price']]\n",
        "\n",
        "# Displaying the first few rows of the compare_result DataFrame\n",
        "print(compare_result.head())"
      ],
      "metadata": {
        "id": "ZLLgURU8I37h"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}