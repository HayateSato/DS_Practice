{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOH4OUdOTny000fItKfOD0W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HayateSato/DS_Practice/blob/main/Learning_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9IzifK7qnfmq",
        "outputId": "bc2c404a-eaf0-4964-8846-77bde96e2de9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3, 4])\n",
            "cpu\n",
            "torch.int64\n"
          ]
        }
      ],
      "source": [
        "# Import PyTorch\n",
        "import torch\n",
        "\n",
        "list_a = [1, 2, 3, 4]\n",
        "\n",
        "# Create a tensor from list_a\n",
        "tensor_a = torch.tensor(list_a)\n",
        "list_a\n",
        "\n",
        "print(tensor_a)\n",
        "\n",
        "# Display the tensor device\n",
        "print(tensor_a.device)\n",
        "\n",
        "# Display the tensor data type\n",
        "print(tensor_a.dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tensor can be calculated like numpy array"
      ],
      "metadata": {
        "id": "rTJvgtRzpgfo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "array_a = [1, 2, 3, 4]\n",
        "array_b = [5, 6, 7, 8]\n",
        "\n",
        "# Create two tensors from the arrays\n",
        "tensor_a = torch.tensor(array_a)\n",
        "tensor_b = torch.tensor(array_b)\n",
        "print(f\"a: {tensor_a}\")\n",
        "print(f\"b: {tensor_b}\")\n",
        "\n",
        "# Subtract tensor_b from tensor_a\n",
        "tensor_c = tensor_a - tensor_b\n",
        "print(f\"c: {tensor_c}\")\n",
        "\n",
        "# Multiply each element of tensor_a with each element of tensor_b\n",
        "tensor_d = tensor_a * tensor_b\n",
        "print(f\"d: {tensor_d}\")\n",
        "\n",
        "# Add tensor_c to tensor_d\n",
        "tensor_e = tensor_c + tensor_d\n",
        "print(f\"e: {tensor_e}\")\n",
        "\n",
        "# concatenating\n",
        "tensor_f = torch.cat((tensor_a, tensor_b))\n",
        "print(f\"f: {tensor_f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVlGSWpxoLWG",
        "outputId": "7dfbd570-677a-4c90-f786-94453a574812"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a: tensor([1, 2, 3, 4])\n",
            "b: tensor([5, 6, 7, 8])\n",
            "c: tensor([-4, -4, -4, -4])\n",
            "d: tensor([ 5, 12, 21, 32])\n",
            "e: tensor([ 1,  8, 17, 28])\n",
            "f: tensor([1, 2, 3, 4, 5, 6, 7, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Nueral Netowork"
      ],
      "metadata": {
        "id": "TZkyv0ImpsEZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "input_tensor = torch.Tensor([[2, 3, 6, 7, 9, 3, 2, 1]])  ### if you want to defin a tensor direclty without using a variable, you need double [[ ]]\n",
        "\n",
        "# Implement a small neural network with exactly two linear layers\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(8, 1),\n",
        "    nn.Linear(1, 1)\n",
        "                     )\n",
        "\n",
        "output = model(input_tensor)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ueCI-rdpvKZ",
        "outputId": "0caedb77-78f3-4da2-dbda-fe6b73f64c73"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3729]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "at the end of the nn, you need to activate it by calling a function such as\n",
        "- Sigmoid\n",
        "- Softmax\n",
        "- ReLU\n",
        "- LU\n",
        "etc.\n",
        "\n",
        "**Sigmoid is used for binary classification methods where we only have 2 classes, while SoftMax applies to multiclass problem**"
      ],
      "metadata": {
        "id": "UtBhFns7yDiJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### sigmoid function"
      ],
      "metadata": {
        "id": "LKPfY7BNqX5e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_tensor = torch.tensor([[0.8]])\n",
        "\n",
        "# Create a sigmoid function and apply it on input_tensor\n",
        "sigmoid = nn.Sigmoid()\n",
        "probability = sigmoid(input_tensor)\n",
        "print(probability)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAFL4lRwqbDg",
        "outputId": "5c464835-6de0-4a31-f781-e0e16d462e8d"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6900]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_tensor = torch.Tensor([[3, 4, 6, 7, 10, 12, 2, 3, 6, 8, 9]])\n",
        "\n",
        "# Implement a neural network with exactly four linear layers\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(11, 4),\n",
        "    nn.Linear(4,3),\n",
        "    nn.Linear(3,2),\n",
        "    nn.Linear(2,1),\n",
        "    nn.Sigmoid()\n",
        ")\n",
        "\n",
        "output = model(input_tensor)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXqsgwC-xH7P",
        "outputId": "b458ca22-1b0d-445e-bcf2-252216e5b0a5"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4793]], grad_fn=<SigmoidBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### softmax function"
      ],
      "metadata": {
        "id": "rXuipbRmve9w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_tensor = torch.tensor([[1.0, -6.0, 2.5, -0.3, 1.2, 0.8]])\n",
        "\n",
        "# Create a softmax function and apply it on input_tensor\n",
        "softmax = nn.Softmax()\n",
        "probabilities = softmax(input_tensor)\n",
        "print(probabilities)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FnBs927vdoB",
        "outputId": "dcf76fd9-5e68-4894-fdab-c00b9591fd7a"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.2828e-01, 1.1698e-04, 5.7492e-01, 3.4961e-02, 1.5669e-01, 1.0503e-01]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1553: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_tensor = torch.Tensor([[3, 4, 6, 7, 10, 12, 2, 3, 6, 8, 9]])\n",
        "\n",
        "# Update network below to perform a multi-class classification with four labels\n",
        "model = nn.Sequential(\n",
        "  nn.Linear(11, 20),\n",
        "  nn.Linear(20, 12),\n",
        "  nn.Linear(12, 6),\n",
        "  nn.Linear(6, 4),\n",
        "  nn.Softmax()\n",
        ")\n",
        "\n",
        "output = model(input_tensor)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGp4OwKaxNV2",
        "outputId": "7f82dd4a-36de-42d0-dd1f-bf3646d1f217"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0804, 0.1197, 0.0484, 0.7515]], grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hot Encoding\n",
        "One-hot encoding is a technique that turns a single integer label into a vector of N elements, where N is the number of classes in your dataset\n",
        "\n",
        " how to this encoding compare with / without pytorch.\n",
        "    1. first without\n",
        "    2. then with pytorch"
      ],
      "metadata": {
        "id": "PAv4mULtyoPx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# without using pytorch\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "\n",
        "y = 1\n",
        "num_classes = 3\n",
        "\n",
        "# Create the one-hot encoded vector using NumPy\n",
        "one_hot_numpy = np.array([0, 1, 0])\n",
        "\n",
        "# Create the one-hot encoded vector using PyTorch\n",
        "one_hot_pytorch = F.one_hot(torch.tensor(y), num_classes)\n",
        "\n",
        "print(one_hot_numpy)\n",
        "print(one_hot_pytorch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hoknizmWw-Tt",
        "outputId": "3188e281-390b-4bcc-e08f-b9c3ed892d61"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 0]\n",
            "tensor([0, 1, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import CrossEntropyLoss\n",
        "\n",
        "y = [2]\n",
        "scores = torch.tensor([[0.1, 6.0, -2.0, 3.2]])\n",
        "num_scores_tensors = scores.shape[1]\n",
        "\n",
        "# Create a one-hot encoded vector of the label y\n",
        "one_hot_label = F.one_hot(torch.tensor(y), num_classes = num_scores_tensors)  ### converting the result of y into one-hot encoded vector to save it\n",
        "\n",
        "# Create the cross entropy loss function\n",
        "criterion = CrossEntropyLoss()\n",
        "\n",
        "# Calculate the cross entropy loss\n",
        "loss = criterion(scores.double(), one_hot_label.double())\n",
        "print(loss)\n",
        "\n",
        "\n",
        "print(scores)\n",
        "print(one_hot_label)\n",
        "print(criterion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MikIK8s43X8T",
        "outputId": "b9552ef7-df95-45b3-e14f-fbd92d88c8a7"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(8.0619, dtype=torch.float64)\n",
            "tensor([[ 0.1000,  6.0000, -2.0000,  3.2000]])\n",
            "tensor([[0, 0, 1, 0]])\n",
            "CrossEntropyLoss()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Calculate the loss\n",
        "loss = criterion(scores, torch.tensor(y))\n",
        "\n",
        "# Compute the gradients of the loss\n",
        "loss.backward()\n",
        "\n",
        "# Display gradients of the weight and bias tensors in order\n",
        "# print(weight.grad)\n",
        "# print(bias.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "FgdzM2lAjkVX",
        "outputId": "a7a18c31-68aa-4d97-ac88-329f59a416ac"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-d773572b6394>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Compute the gradients of the loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Display gradients of the weight and bias tensors in order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    519\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m             )\n\u001b[0;32m--> 521\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    290\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    767\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 769\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    770\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "weight =  torch.randn(2, 9, requires_grad=True)\n",
        "bias = torch.randn(2, requires_grad=True)\n",
        "preds = torch.randn(1, 2, requires_grad=True)\n",
        "target = torch.tensor([[1.0, 0.0]], requires_grad=False)\n",
        "\n",
        "# Calculate the loss\n",
        "loss = criterion(preds, target)\n",
        "\n",
        "# Compute the gradients of the loss\n",
        "loss.backward()\n",
        "\n",
        "# Display gradients of the weight and bias tensors in order\n",
        "print(weight.grad)\n",
        "print(bias.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_o1tK8kqkUF3",
        "outputId": "3cbdf6fc-2471-41c5-b0a8-b0f36993c5df"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "8IVOwkfClv1l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### each layer parameter can be accessed by indexing the created model directly\n",
        "\n",
        "model = nn.Sequential(nn.Linear(16, 8),\n",
        "                      nn.Sigmoid(),\n",
        "                      nn.Linear(8, 2))\n",
        "\n",
        "# Access the weight of the first linear layer\n",
        "weight_0 =  model[0].weight\n",
        "\n",
        "# Access the bias of the second linear layer\n",
        "bias_1 = model[2].bias\n",
        "\n",
        "print(model)\n",
        "# Sequential(\n",
        "#   (0): Linear(in_features=16, out_features=8, bias=True)\n",
        "#   (1): Sigmoid()\n",
        "#   (2): Linear(in_features=8, out_features=2, bias=True)\n",
        "# )\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4A7RcMklkTR",
        "outputId": "42fc3d36-5c03-47e9-ed5c-8d921a778290"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=16, out_features=8, bias=True)\n",
            "  (1): Sigmoid()\n",
            "  (2): Linear(in_features=8, out_features=2, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Create the optimizer\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "loss = criterion(preds, target)\n",
        "loss.backward()\n",
        "\n",
        "# Update the model's parameters using the optimizer\n",
        "optimizer.step()"
      ],
      "metadata": {
        "id": "K5oELSjWmNgO"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HEzmypvPml60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "   "
      ],
      "metadata": {
        "id": "JBQCM_0zzq9U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "TRSdeEH64EdQ"
      }
    }
  ]
}